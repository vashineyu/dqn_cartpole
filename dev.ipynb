{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import os\n",
    "import numpy as np\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "from cartpole.config import get_cfg_defaults\n",
    "from cartpole.utils import ReplayMemory, screen_to_state\n",
    "from cartpole.model import DQN\n",
    "\n",
    "\n",
    "\n",
    "cfg = get_cfg_defaults()\n",
    "\n",
    "devices = \",\".join(str(i) for i in cfg.SYSTEM.DEVICES)\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If you want to access the behind-the.scenes dynamics of a specific environment, \n",
    "then you use the unwrapped property.\n",
    "\"\"\"\n",
    "display = Display(visible=0, size=cfg.SYSTEM.VIRTUAL_SCREEN)\n",
    "display.start()\n",
    "env = gym.make(\"CartPole-v0\").unwrapped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#policy_net = DQN(2)\n",
    "#target_net = DQN(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import models, layers\n",
    "\n",
    "class Brain(models.Model):\n",
    "    def __init__(self, policy_net, target_net, gamma):\n",
    "        super(Brain, self).__init__()\n",
    "        self.policy_net = policy_net\n",
    "        self.target_net = target_net\n",
    "        self.loss_layer = LossLayer(name=\"TDerror\")\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        self.policy_net.trainable = False\n",
    "        \n",
    "    def call(self, x):\n",
    "        state, action, next_state, reward, done = x\n",
    "        state = tf.convert_to_tensor(state, dtype=tf.float32)\n",
    "        action = tf.convert_to_tensor(action, dtype=tf.float32)\n",
    "        next_state = tf.convert_to_tensor(next_state, dtype=tf.float32)\n",
    "        reward = tf.convert_to_tensor(reward, dtype=tf.float32)\n",
    "        done = tf.convert_to_tensor(done, dtype=tf.float32)\n",
    "        \n",
    "        bz = K.shape(state)[0] # state.shape.as_list()[0]\n",
    "        target = reward + (1-done) * self.gamma * tf.gather_nd(self.target_net(next_state), \n",
    "                                                               tf.stack((tf.range(bz), \n",
    "                                                                         tf.cast(tf.argmax(self.policy_net(state), \n",
    "                                                                                           axis=1), dtype=tf.int32)), axis=1))\n",
    "        estimate = tf.gather_nd(self.policy_net(state), \n",
    "                                tf.stack((tf.range(bz), \n",
    "                                          tf.cast(action, dtype=tf.int32) ), axis=1))\n",
    "        loss = self.loss_layer([target, estimate])\n",
    "        \"\"\"\n",
    "        loss = tf.keras.losses.MSE(target, estimate)\n",
    "        self.add_loss(loss)\n",
    "        \"\"\"\n",
    "        return target, estimate\n",
    "    \n",
    "class LossLayer(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(LossLayer, self).__init__(**kwargs)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        print(inputs[0])\n",
    "        print(inputs[1])\n",
    "        loss = K.square(K.mean(inputs[0]-inputs[1]))\n",
    "        self.add_loss(loss)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#policy_net.build(input_shape=(1, 60,60,3))\n",
    "#target_net.build(input_shape=(1, 60,60,3))\n",
    "#x = policy_net.weights[0]\n",
    "\n",
    "\n",
    "#for i,j in zip(policy_net.layers, target_net.layers):\n",
    "#    i.set_weights(j.get_weights())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent.py\n",
    "from cartpole.utils import Transition\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "import random\n",
    "\n",
    "\n",
    "class DqnAgent():\n",
    "    def __init__(self, input_shape=(128, 128, 3), \n",
    "                 action_space=2, \n",
    "                 soft_update_ratio=0.01,\n",
    "                 gamma=0.99,\n",
    "                 memory=None,\n",
    "                 eps_start=0.9, eps_end=0.05, eps_decay=200,\n",
    "                 batch_size=128,\n",
    "                 fully_random_mode=False,\n",
    "                 ):\n",
    "        self.action_space = action_space\n",
    "        self.soft_update_ratio = soft_update_ratio\n",
    "        self.gamma = gamma\n",
    "        self.memory = memory\n",
    "        self.eps = eps_start\n",
    "        self.eps_start = eps_start\n",
    "        self.eps_end = eps_end\n",
    "        self.eps_decay = eps_decay\n",
    "        self.batch_size = batch_size\n",
    "        self.fully_random_mode = fully_random_mode\n",
    "        \n",
    "        K.clear_session()\n",
    "        self.policy_net = DQN(action_space) # action giver\n",
    "        self.target_net = DQN(action_space) # action learner\n",
    "        self.policy_net.build(input_shape=(1,)+input_shape)\n",
    "        self.target_net.build(input_shape=(1,)+input_shape)\n",
    "        #self._soft_update() # sync weights at begining\n",
    "        \n",
    "        self.step_done = 0\n",
    "    \n",
    "    def act(self, state):\n",
    "        \"\"\" Decide to random act or follow policy\"\"\"\n",
    "        dice = random.random()\n",
    "        if (dice < self.eps) or (self.fully_random_mode):\n",
    "            # Random act\n",
    "            action = np.random.choice(self.action_space)\n",
    "        else:\n",
    "            # Follow policy\n",
    "            action = self.policy_net.predict(state)\n",
    "        self._update_eps()\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    def learn(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return\n",
    "        \n",
    "        transition = self.memory.sample(self.batch_size)\n",
    "        batch = Transition(*zip(*transition))\n",
    "    \n",
    "    def _soft_update(self):\n",
    "        [j.set_weights(i.get_weights() + j.get_weights()) \\\n",
    "         for i,j in zip(self.policy_net.layers, self.target_net.layers)]\n",
    "        \n",
    "    def _update_eps(self):\n",
    "        self.eps = self.eps_end + (self.eps_start - self.eps_end)*np.exp(-1.*self.step_done/self.eps_decay)\n",
    "        self.step_done += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/seanyu/.conda/envs/pyttf/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "memory = ReplayMemory(capacity=10000)\n",
    "agent = DqnAgent(action_space=env.action_space.n, gamma=cfg.AGENT.GAMMA, memory=memory,\n",
    "                 eps_start=cfg.AGENT.EPS_START, eps_end=cfg.AGENT.EPS_END, eps_decay=cfg.AGENT.EPS_DECAY,\n",
    "                 batch_size=cfg.AGENT.BATCH_SIZE, \n",
    "                 input_shape=cfg.MODEL.INPUT_SIZE,\n",
    "                 fully_random_mode=True,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cfg.AGENT.NUM_EPISODE\n",
    "for i_episode in range(2):\n",
    "    env.reset()\n",
    "    last_screen = screen_to_state(env, target_size=cfg.MODEL.INPUT_SIZE[:2])\n",
    "    current_screen = screen_to_state(env, target_size=cfg.MODEL.INPUT_SIZE[:2])\n",
    "    state = current_screen - last_screen\n",
    "    \n",
    "    for t_counter in range(cfg.AGENT.MAX_T):\n",
    "        action = agent.act(state)\n",
    "        \n",
    "        vector_state, reward, is_done, _ = env.step(action)\n",
    "        \n",
    "        last_screen = current_screen\n",
    "        current_screen = screen_to_state(env, target_size=cfg.MODEL.INPUT_SIZE[:2])\n",
    "        if not is_done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "            \n",
    "        memory.push(state, action, next_state, reward, is_done)\n",
    "        state = next_state\n",
    "        \n",
    "        # Train the model\n",
    "        agent.learn()\n",
    "        \n",
    "        if is_done:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = agent.memory.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Transition(*zip(*m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.Variable(np.array(b.state), dtype=tf.float32)\n",
    "a = tf.Variable(np.array(b.action), dtype=tf.float32)\n",
    "sn = tf.Variable(np.array(b.next_state), dtype=tf.float32)\n",
    "r = tf.Variable(np.array(b.reward), dtype=tf.float32)\n",
    "d =  tf.Variable(np.array(b.done)*1, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_brain = Brain(policy_net=agent.policy_net, target_net=agent.target_net, gamma=0.9)\n",
    "optim = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y_true, y_pred):\n",
    "    return K.square(K.mean(y_true-y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_brain.total_loss = 0\n",
    "new_brain.compile(optimizer=optim, loss=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Not implementedError ...\n",
    "with tf.GradientTape() as tape:\n",
    "    loss = new_brain([np.array(b.state), \n",
    "                      np.array(b.action), \n",
    "                      np.array(b.next_state),\n",
    "                      np.array(b.reward), \n",
    "                      np.array(b.done)*1])\n",
    "grads = tape.gradient(loss, new_brain.trainable_variables)\n",
    "\"\"\" \n",
    "#new_brain.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"brain_3_2/add:0\", shape=(4,), dtype=float32)\n",
      "Tensor(\"brain_3_2/GatherNd_1:0\", shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "target, estimate = new_brain(batch)\n",
    "loss = compute_loss(target, estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = tf.gradients(loss, new_brain.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'output_2_target' with dtype float and shape [?]\n\t [[{{node output_2_target}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-f12fa45c5896>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m          \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m          np.array(b.done)*1]\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mnew_brain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/pyttf/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1186\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pyttf/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/.conda/envs/pyttf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pyttf/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'output_2_target' with dtype float and shape [?]\n\t [[{{node output_2_target}}]]"
     ]
    }
   ],
   "source": [
    "batch = [np.array(b.state), \n",
    "         np.array(b.action), \n",
    "         np.array(b.next_state),\n",
    "         np.array(b.reward), \n",
    "         np.array(b.done)*1]\n",
    "new_brain.train_on_batch(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'TDerror_1/Square:0' shape=() dtype=float32>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_brain.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(screen_to_state(env))\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
